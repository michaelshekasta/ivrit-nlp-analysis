{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8146340,"sourceType":"datasetVersion","datasetId":4817329}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-25T07:20:51.737930Z","iopub.execute_input":"2024-04-25T07:20:51.739158Z","iopub.status.idle":"2024-04-25T07:20:52.638053Z","shell.execute_reply.started":"2024-04-25T07:20:51.739119Z","shell.execute_reply":"2024-04-25T07:20:52.636960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers --upgrade","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:20:52.640066Z","iopub.execute_input":"2024-04-25T07:20:52.640572Z","iopub.status.idle":"2024-04-25T07:21:18.062091Z","shell.execute_reply.started":"2024-04-25T07:20:52.640532Z","shell.execute_reply":"2024-04-25T07:21:18.061131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:21:18.063493Z","iopub.execute_input":"2024-04-25T07:21:18.063784Z","iopub.status.idle":"2024-04-25T07:21:30.956122Z","shell.execute_reply.started":"2024-04-25T07:21:18.063759Z","shell.execute_reply":"2024-04-25T07:21:30.954974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datasets --upgrade","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:21:30.958889Z","iopub.execute_input":"2024-04-25T07:21:30.959280Z","iopub.status.idle":"2024-04-25T07:21:45.065084Z","shell.execute_reply.started":"2024-04-25T07:21:30.959245Z","shell.execute_reply":"2024-04-25T07:21:45.064146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import load_dataset, load_metric, Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\nfrom peft import get_peft_config, LoraConfig, TaskType, get_peft_model\n\n# Create DataFrames for training and evaluation data\n\"\"\"\ntrain_texts = [\n    \"This is a positive example.\",\n    \"This is another positive example.\",\n    \"This is a negative example.\",\n    # Add more training examples here\n]\n\ntrain_labels = [1, 1, 0]\n\neval_texts = [\n    \"This is a positive evaluation example.\",\n    \"This is a negative evaluation example.\",\n    # Add more evaluation examples here\n]\n\neval_labels = [1, 0]\n\ntrain_data = pd.DataFrame({\"text\": train_texts, \"label\": train_labels})\neval_data = pd.DataFrame({\"text\": eval_texts, \"label\": eval_labels})\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:21:45.066559Z","iopub.execute_input":"2024-04-25T07:21:45.066868Z","iopub.status.idle":"2024-04-25T07:22:02.358823Z","shell.execute_reply.started":"2024-04-25T07:21:45.066840Z","shell.execute_reply":"2024-04-25T07:22:02.357947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string \nimport re\ntranslator = str.maketrans('', '', string.punctuation) ","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:22:02.360031Z","iopub.execute_input":"2024-04-25T07:22:02.360750Z","iopub.status.idle":"2024-04-25T07:22:02.365165Z","shell.execute_reply.started":"2024-04-25T07:22:02.360723Z","shell.execute_reply":"2024-04-25T07:22:02.364151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_target(row):\n    orig_text = row['orig_text'].translate(translator).split()\n    text = row['text'].translate(translator).split()\n    return 1 if orig_text == text  else 0","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:22:02.366601Z","iopub.execute_input":"2024-04-25T07:22:02.366994Z","iopub.status.idle":"2024-04-25T07:22:02.393585Z","shell.execute_reply.started":"2024-04-25T07:22:02.366958Z","shell.execute_reply":"2024-04-25T07:22:02.392696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/michael-ivrit-dataset/train_data.csv', index_col=None).dropna()\neval_data = pd.read_csv('/kaggle/input/michael-ivrit-dataset/test_data.csv', index_col=None).dropna()\ntrain_data['label'] = train_data.apply(calc_target, axis=1)\neval_data['label'] = train_data.apply(calc_target, axis=1)\n\ntrain_data = train_data[['orig_text', 'label']].rename(columns={'orig_text': 'text'})\neval_data = eval_data[['orig_text', 'label']].rename(columns={'orig_text': 'text'})\n# Create a dataset object\ntrain_dataset = Dataset.from_pandas(train_data)\neval_dataset = Dataset.from_pandas(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:22:02.394735Z","iopub.execute_input":"2024-04-25T07:22:02.395016Z","iopub.status.idle":"2024-04-25T07:22:07.108002Z","shell.execute_reply.started":"2024-04-25T07:22:02.394993Z","shell.execute_reply":"2024-04-25T07:22:07.107235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the pre-trained tokenizer and model\nmodel_name = \"xlm-roberta-large\"\nmodel_name = \"xlm-roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Binary classification\n\n# Tokenize the texts\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)\n\ntokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\ntokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:22:07.109150Z","iopub.execute_input":"2024-04-25T07:22:07.109440Z","iopub.status.idle":"2024-04-25T07:22:54.051104Z","shell.execute_reply.started":"2024-04-25T07:22:07.109417Z","shell.execute_reply":"2024-04-25T07:22:54.050180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")\n\n# Configure the LoRA parameters\n# peft_config = LoraConfig(model, TaskType.SEQ_CLS, LoraConfig(r=16, lora_alpha=32))\npeft_config = LoraConfig(\n    task_type=TaskType.SEQ_CLS, inference_mode=False, r=16, lora_alpha=32, lora_dropout=0.1\n)\n\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:22:54.053745Z","iopub.execute_input":"2024-04-25T07:22:54.054072Z","iopub.status.idle":"2024-04-25T07:22:54.123620Z","shell.execute_reply.started":"2024-04-25T07:22:54.054044Z","shell.execute_reply":"2024-04-25T07:22:54.122497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the Trainer\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    learning_rate=1e-5,\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=64,\n    num_train_epochs=50,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    report_to='tensorboard'\n)\n\nmetric = load_metric(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(-1)\n    return metric.compute(predictions=predictions, references=labels)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_eval_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    data_collator=data_collator,\n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate the model\neval_result = trainer.evaluate()\n\nprint(f\"Evaluation result: {eval_result}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:22:54.125066Z","iopub.execute_input":"2024-04-25T07:22:54.125726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(\"output_dir\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}